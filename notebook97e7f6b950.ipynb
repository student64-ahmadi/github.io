{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10193534,"sourceType":"datasetVersion","datasetId":6298384},{"sourceId":10202087,"sourceType":"datasetVersion","datasetId":6304552}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"import sqlite3\nimport pandas as pd\n\n# File paths\nfile_2019 = '/kaggle/input/trip-data/Divvy_Trips_2019_Q1/Divvy_Trips_2019_Q1.csv'\nfile_2020 = '/kaggle/input/trip-data/Divvy_Trips_2020_Q1 (1)/Divvy_Trips_2020_Q1.csv'\n\n# Load CSVs into pandas\ndata_2019 = pd.read_csv(file_2019)\ndata_2020 = pd.read_csv(file_2020)\n\n# Connect to SQLite database\nconn = sqlite3.connect('bike_share.db')\n\n# Import data into SQLite tables\ndata_2019.to_sql('trips_2019', conn, if_exists='replace', index=False)\ndata_2020.to_sql('trips_2020', conn, if_exists='replace', index=False)\n\nprint(\"Data imported into SQLite database.\")\n","metadata":{}},{"cell_type":"markdown","source":"Solution_case_study1 Cyclitic Bike-share Case study1\n AHMADI OTHMAN 2024-12-21\n Hi everyone, I’ve been working on the Google Data Analytics Professional Certificate through Coursera. This capstone project is the final project in my Google Data Analytics Professional Certificate course.\nBusiness Task Cyclistic aims to increase annual memberships by understanding differences in bike usage between casual riders and members. Insights from this analysis will inform marketing strategies to convert casual riders into annual members. In this case study, we tasked to analyze a public dataset for a fictional company provided by the course. I used Python programming language and Kaggle motebook for data analysis and visulisation\nData Sources:\no\tCyclistic bike-share trip data for 2019-2020 ( CSV files). \no\t Data included fields such as trip start/end times, ride length, and rider type       (casual vs. member).\no\t The following data analysis steps will be followed: Ask, Prepare, Process, Analyze, Share, Act.\n1.\tAsk\n The questions that need to be answered are:\n•\tHow do annual members and casual riders use Cyclistic bikes differently? Why would casual riders buy Cyclistic annual memberships?\n•\t How can Cyclistic use digital media to influence casual riders to become members? Analysis for the three guiding questions:\n•\tHow do annual members and casual riders use Cyclistic bikes differently? To analyze this, we can focus on the usertype, tripduration, and start_time/end_time columns:\n2.\tCleaning data \nData cleaning included converting time columns to datetime formats, removing anomalies in ride lengths, and ensuring consistent formatting across datasets.\n3.\tAnalysis for the first guiding question: \n\nHow do annual members and casual riders use Cyclistic bikes differently?\nTo analyze this, we focused on the following:\n•\tTrip Frequency: Group trips by user type to compare the number of trips.\n•\tTrip Duration: Analyze the trip duration to understand usage patterns.\n•\tTime of Use: Identify trends based on the hour of the day and day of the week.\n________________________________________\n","metadata":{}},{"cell_type":"code","source":"import sqlite3\nimport pandas as pd\n\n# File paths\nfile_2019 = '/kaggle/input/trip-data/Divvy_Trips_2019_Q1/Divvy_Trips_2019_Q1.csv'\nfile_2020 = '/kaggle/input/trip-data/Divvy_Trips_2020_Q1 (1)/Divvy_Trips_2020_Q1.csv'\n\n# Load CSVs into pandas\ndata_2019 = pd.read_csv(file_2019)\ndata_2020 = pd.read_csv(file_2020)\n\n# Connect to SQLite database\nconn = sqlite3.connect('bike_share.db')\n\n# Import data into SQLite tables\ndata_2019.to_sql('trips_2019', conn, if_exists='replace', index=False)\ndata_2020.to_sql('trips_2020', conn, if_exists='replace', index=False)\n\nprint(\"Data imported into SQLite database.\")\n\n# Step 2: Check total number of rows\nquery = \"\"\"\nSELECT \n    'trips_2019' AS table_name, COUNT(*) AS total_rows \nFROM trips_2019\nUNION ALL\nSELECT \n    'trips_2020', COUNT(*) \nFROM trips_2020;\n\"\"\"\nprint(pd.read_sql_query(query, conn))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conn.execute(\"DROP TABLE IF EXISTS combined_trips;\")\nprint(pd.read_sql_query(\"PRAGMA table_info(trips_2019);\", conn))\nprint(pd.read_sql_query(\"PRAGMA table_info(trips_2020);\", conn))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:09:49.743019Z","iopub.execute_input":"2024-12-21T19:09:49.743513Z","iopub.status.idle":"2024-12-21T19:09:51.737336Z","shell.execute_reply.started":"2024-12-21T19:09:49.743490Z","shell.execute_reply":"2024-12-21T19:09:51.736203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport sqlite3\nimport numpy as np\n\n# **Step 1: Load Data**\nfile_2019 = '/kaggle/input/trip-data/Divvy_Trips_2019_Q1/Divvy_Trips_2019_Q1.csv'\nfile_2020 = '/kaggle/input/trip-data/Divvy_Trips_2020_Q1 (1)/Divvy_Trips_2020_Q1.csv'\n\n# Load CSVs into pandas\ndata_2019 = pd.read_csv(file_2019)\ndata_2020 = pd.read_csv(file_2020)\n\n# Harmonize column names\ndata_2019.rename(columns={\n    'start_time': 'started_at',\n    'end_time': 'ended_at',\n    'from_station_name': 'start_station_name',\n    'to_station_name': 'end_station_name',\n    'usertype': 'member_casual'\n}, inplace=True)\n\n# Ensure `member_casual` consistency\ndata_2019['member_casual'] = data_2019['member_casual'].replace({\n    'Subscriber': 'member',\n    'Customer': 'casual'\n})\n\n# Create ride_length and day_of_week for both datasets\nfor df in [data_2019, data_2020]:\n    df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')\n    df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')\n    df['ride_length'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60  # in minutes\n    df['day_of_week'] = df['started_at'].dt.dayofweek + 1  # Monday=1, Sunday=7\n\n# Filter out invalid ride lengths\ndata_2019 = data_2019[(data_2019['ride_length'] > 0) & (data_2019['ride_length'] < 1440)]\ndata_2020 = data_2020[(data_2020['ride_length'] > 0) & (data_2020['ride_length'] < 1440)]\n\n# **Step 2: Store Data in SQLite**\nconn = sqlite3.connect('bike_share.db')\ndata_2019.to_sql('trips_2019', conn, if_exists='replace', index=False)\ndata_2020.to_sql('trips_2020', conn, if_exists='replace', index=False)\nquery = \"DROP TABLE IF EXISTS combined_trips;\"\nconn.execute(query)  # Drop the table if it exists\n\n# Connect to SQLite database\nconn = sqlite3.connect('bike_share.db')\n\n# Add ride_length and day_of_week columns\nfor df in [data_2019, data_2020]:\n    df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')\n    df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')\n    df['ride_length'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n    df['day_of_week'] = df['started_at'].dt.dayofweek + 1  # Monday=1, Sunday=7\n\n# Save to SQLite\ndata_2019.to_sql('trips_2019', conn, if_exists='replace', index=False)\ndata_2020.to_sql('trips_2020', conn, if_exists='replace', index=False)\n\n# Drop the existing table if it exists\nconn.execute(\"DROP TABLE IF EXISTS combined_trips;\")\n\n# Combine tables with aligned columns\nquery = \"\"\"\nCREATE TABLE combined_trips AS\nSELECT \n    '2019' AS year,\n    trip_id,\n    started_at,\n    ended_at,\n    bikeid,\n    tripduration,\n    from_station_id,\n    start_station_name,\n    to_station_id,\n    end_station_name,\n    member_casual,\n    gender,\n    birthyear,\n    ride_length,\n    day_of_week,\n    NULL AS rideable_type,\n    NULL AS start_lat,\n    NULL AS start_lng,\n    NULL AS end_lat,\n    NULL AS end_lng\nFROM trips_2019\nUNION ALL\nSELECT \n    '2020' AS year,\n    ride_id AS trip_id,\n    started_at,\n    ended_at,\n    NULL AS bikeid,\n    NULL AS tripduration,\n    start_station_id AS from_station_id,\n    start_station_name,\n    end_station_id AS to_station_id,\n    end_station_name,\n    member_casual,\n    NULL AS gender,\n    NULL AS birthyear,\n    ride_length,\n    day_of_week,\n    rideable_type,\n    start_lat,\n    start_lng,\n    end_lat,\n    end_lng\nFROM trips_2020;\n\"\"\"\nconn.execute(query)\nprint(\"Tables combined into 'combined_trips'.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:08:50.465772Z","iopub.execute_input":"2024-12-21T19:08:50.466048Z","iopub.status.idle":"2024-12-21T19:09:08.654539Z","shell.execute_reply.started":"2024-12-21T19:08:50.466029Z","shell.execute_reply":"2024-12-21T19:09:08.653693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport sqlite3\nimport numpy as np\n\n\n# Summary statistics for ride_length\nquery = \"\"\"\nSELECT \n    member_casual,\n    AVG(ride_length) AS avg_length,\n    MAX(ride_length) AS max_length,\n    COUNT(*) AS total_rides\nFROM combined_trips\nGROUP BY member_casual;\n\"\"\"\nprint(pd.read_sql_query(query, conn))\n\n# **Step 4: Create Pivot Tables**\n# Average ride length for members and casual riders\npivot_avg_length = pd.read_sql_query(\"\"\"\nSELECT \n    member_casual,\n    AVG(ride_length) AS avg_length\nFROM combined_trips\nGROUP BY member_casual;\n\"\"\", conn)\n\n# Average ride length by day_of_week and user type\npivot_avg_length_by_day = pd.read_sql_query(\"\"\"\nSELECT \n    day_of_week,\n    member_casual,\n    AVG(ride_length) AS avg_length\nFROM combined_trips\nGROUP BY day_of_week, member_casual;\n\"\"\", conn)\n\n# Number of rides by day_of_week\npivot_count_rides_by_day = pd.read_sql_query(\"\"\"\nSELECT \n    day_of_week,\n    member_casual,\n    COUNT(*) AS total_rides\nFROM combined_trips\nGROUP BY day_of_week, member_casual;\n\"\"\", conn)\n\n# **Step 5: Export Pivot Tables**\npivot_avg_length.to_csv('/kaggle/working/pivot_avg_length.csv', index=False)\npivot_avg_length_by_day.to_csv('/kaggle/working/pivot_avg_length_by_day.csv', index=False)\npivot_count_rides_by_day.to_csv('/kaggle/working/pivot_count_rides_by_day.csv', index=False)\n\n# **Step 6: Visualizations**\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualization 1: Average ride length by user type\nplt.figure(figsize=(8, 6))\nsns.barplot(data=pivot_avg_length, x='member_casual', y='avg_length', palette='Set2')\nplt.title('Average Ride Length by User Type')\nplt.xlabel('User Type')\nplt.ylabel('Average Ride Length (Minutes)')\nplt.grid(axis='y')\nplt.savefig('/kaggle/working/avg_ride_length_by_user.png')\nplt.show()\n\n# Visualization 2: Average ride length by day_of_week\npivot_avg_length_by_day = pivot_avg_length_by_day.pivot(index='member_casual', columns='day_of_week', values='avg_length')\npivot_avg_length_by_day.plot(kind='bar', figsize=(10, 6), colormap='Set1')\nplt.title('Average Ride Length by Day of the Week and User Type')\nplt.xlabel('User Type')\nplt.ylabel('Average Ride Length (Minutes)')\nplt.legend(title='Day of Week', loc='upper left')\nplt.grid(axis='y')\nplt.savefig('/kaggle/working/avg_ride_length_by_day.png')\nplt.show()\n\n# Visualization 3: Number of rides by day_of_week\npivot_count_rides_by_day = pivot_count_rides_by_day.pivot(index='member_casual', columns='day_of_week', values='total_rides')\npivot_count_rides_by_day.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='Accent')\nplt.title('Number of Rides by Day of the Week and User Type')\nplt.xlabel('User Type')\nplt.ylabel('Number of Rides')\nplt.legend(title='Day of Week', loc='upper left')\nplt.grid(axis='y')\nplt.savefig('/kaggle/working/ride_counts_by_day.png')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:09:16.484950Z","iopub.execute_input":"2024-12-21T19:09:16.485249Z","iopub.status.idle":"2024-12-21T19:09:19.913427Z","shell.execute_reply.started":"2024-12-21T19:09:16.485230Z","shell.execute_reply":"2024-12-21T19:09:19.912722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualizations and Key Findings\n1. Number of Rides by Day of the Week\nInterpretation: Members show consistent activity across weekdays, while casual riders dominate on weekends, reflecting leisure usage.\n2. Average Ride Duration by Day\nInterpretation: Casual riders have longer rides, especially on weekends, whereas members maintain consistent ride durations.\n3. Ride Duration Distribution\nInterpretation: Boxplots show casual riders have higher variability and longer outliers in ride durations compared to members.\n","metadata":{}},{"cell_type":"markdown","source":"This bar chart visualizes the average ride length for different user types (casual and member) across each day of the week. Here's the analysis and some recommendations based on the data:\n________________________________________\nAnalysis\n1.\tCasual Riders:\no\tHave longer ride lengths consistently across the week, with peaks on weekends (Day 6 and Day 7).\no\tThis trend suggests that casual riders use the service more for leisure and recreational activities during their free time.\n2.\tMembers:\no\tExhibit steady ride lengths throughout the week, with only slight variations.\no\tThis indicates members predominantly use the service for consistent, routine purposes like commuting, regardless of the day.\n3.\tDay-Specific Trends:\no\tThe ride lengths for casual users increase significantly on weekends, while members’ ride lengths show little change.\no\tCasual users' highest ride lengths appear on Day 6 and Day 7 (Saturday and Sunday).\n________________________________________\nRecommendations\n1.\tService Optimization:\no\tAllocate more bikes and staff at high-demand stations on weekends to accommodate the surge in casual riders.\no\tFor members, maintain steady availability during weekdays, especially around commuting hours.\n2.\tMarketing and Engagement:\no\tFor casual users: Introduce weekend-specific offers, such as group discounts or extended ride time without extra charges.\no\tFor members: Incentivize weekend usage by offering small rewards or loyalty points for weekend rides.\n","metadata":{}},{"cell_type":"markdown","source":"RECOMMANDATIONS\n1.\tTargeted Promotions Based on Trip Duration: Cyclistic could create digital campaigns targeting casual riders who make frequent short trips, emphasizing that an annual membership would provide them with better value and convenience (particularly if they take multiple trips in a given month).\n2.\tIncentivizing Frequent Riders: For casual riders who tend to use bikes consistently over a short period (e.g., several trips in a week or month), digital media could highlight how switching to a membership would eliminate the hassle of paying for individual rides and allow them to enjoy more rides at no extra cost. \n3.\tPromote annual memberships to occasional users by highlighting the benefits for recreational (weekend) activities. Target members with commuting offers. Integrate these analytics into specific marketing campaigns through digital channels. \n4.\tPush Notifications/Email Campaigns: Casual riders who have frequent trips but not necessarily the longest durations might be enticed by a special offer that shows how much they would save with a membership over time. This can be done through push notifications or emails, with a clear breakdown of savings based on their tripduration patterns.\n","metadata":{}}]}